{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API documentation \n",
    "https://cloud.ibm.com/apidocs/assistant-v2?code=python#listassistants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from ibm_watson import AssistantV2\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API assistant setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.getenv(key='API_KEY')\n",
    "URL = 'https://api.us-east.assistant.watson.cloud.ibm.com/'\n",
    "ASSISTANT_NAME = 'Ask_Proc_Main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "authenticator = IAMAuthenticator(API_KEY)\n",
    "assistant = AssistantV2(\n",
    "    version='2021-06-14',\n",
    "    authenticator = authenticator\n",
    ")\n",
    "\n",
    "assistant.set_service_url(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get List of assistants available\n",
    "\n",
    "This will give you all the assistants that are available in that instance in IBM cloud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistants_list = assistant.list_assistants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bot in assistants_list.get_result().get('assistants'):\n",
    "    if bot.get('name') == ASSISTANT_NAME:\n",
    "        ASSISTANT_ID = bot.get('assistant_id')\n",
    "        pprint.pprint(bot)\n",
    "\n",
    "print(f'\\n\\nYour assistant id is: {ASSISTANT_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you can define the assistant environment to get the logs from \n",
    "ASSISTANT_ENV_ID = '572332fa-74b2-4e42-9c4d-93c891106824'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get log data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get all the logs \n",
    "cursor = None\n",
    "page = 1\n",
    "\n",
    "all_logs = []\n",
    "\n",
    "while True:\n",
    "    print(f'working on page {page}')\n",
    "    page += 1\n",
    "    response=assistant.list_logs(\n",
    "        assistant_id=ASSISTANT_ENV_ID,\n",
    "        cursor=cursor,\n",
    "    ).get_result()\n",
    "\n",
    "    all_logs.extend(response['logs'])\n",
    "\n",
    "    cursor=response.get('pagination').get('next_cursor')\n",
    "    if not cursor:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "response=assistant.list_logs(\n",
    "        assistant_id=ASSISTANT_ENV_ID,\n",
    "    ).get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#to sabe the logs in picke object \n",
    "with open('all_logs.pkl', 'wb') as file: \n",
    "    pickle.dump(all_logs, file=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here to read all the logs from pkl file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read pickle back \n",
    "with open('all_logs.pkl', 'rb') as file:\n",
    "    # Load the pickle object using pickle.load\n",
    "    all_logs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(all_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = 9435\n",
    "print('REQUEST')\n",
    "pprint.pprint(all_logs[log].get('request').get('input'))\n",
    "print('RESPONSE:')\n",
    "pprint.pprint(all_logs[log].get('response').get('output'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all keys for requests \n",
    "request_first_level_keys = set()\n",
    "\n",
    "for log in all_logs:\n",
    "    data = log.get('request').get('input')\n",
    "    keys = data.keys()\n",
    "    for k in keys:\n",
    "        request_first_level_keys.add(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_first_level_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count all keys from request \n",
    "\n",
    "keys_counter = {\n",
    "    'entities': 0,\n",
    "    'filter': 0,\n",
    "    'intents': 0,\n",
    "    'internal': 0,\n",
    "    'message_type': 0,\n",
    "    'options': 0,\n",
    "    'query_type': 0,\n",
    "    'return_to_dialog': 0,\n",
    "    'source': 0,\n",
    "    'suggestion_id': 0,\n",
    "    'text': 0\n",
    "}\n",
    "\n",
    "for log in all_logs:\n",
    "    data = log.get('request').get('input')\n",
    "    keys = data.keys()\n",
    "    for k in keys_counter.keys():\n",
    "        if k in keys:\n",
    "            keys_counter[k] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anlyze the data in each key for request \n",
    "count = 0\n",
    "\n",
    "for log in all_logs:\n",
    "    data = log.get('request').get('input')\n",
    "    keys = data.keys()\n",
    "    if 'suggestion_id' in keys:\n",
    "        pprint.pprint(data)\n",
    "        print('--------END--------')\n",
    "        count += 1\n",
    "    if count == 7:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs[0].get('request').get('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_expander(base_dict):\n",
    "    my_data = {}\n",
    "    change_counts = 0\n",
    "    for key, val in base_dict.items():\n",
    "        if type(val) == dict:\n",
    "            change_counts += 1\n",
    "            for key2, val2 in val.items():\n",
    "                my_data[key+'_'+key2] = val2\n",
    "        if type(val) == str:\n",
    "            my_data[key] = val\n",
    "        if type(val) == list:\n",
    "            if (len(val)>0) and (type(val[0]) == dict):\n",
    "                change_counts += 1\n",
    "                for key3, val3 in val[0].items():\n",
    "                    my_data[key+'_'+key3] = val3\n",
    "            if (len(val)>0) and (type(val[0]) == str):\n",
    "                my_data[key] = val[0]\n",
    "\n",
    "    return my_data, change_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs[0].get('response').get('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "data = {\n",
    "    'log_id': all_logs[0].get('log_id'),\n",
    "    'input': all_logs[0].get('request').get('input')\n",
    "    }\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_while = 0\n",
    "change_counter = 1 \n",
    "\n",
    "while change_counter != 0:\n",
    "    if counter_while == 0:\n",
    "        new_data, change_counter = json_expander(base_dict=data)\n",
    "        counter_while += 1\n",
    "    else: \n",
    "        new_data, change_counter = json_expander(base_dict=new_data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to save logs in able or csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs = pd.DataFrame()\n",
    "\n",
    "for log in all_logs: \n",
    "    temp = {\n",
    "        'log_id' : log.get('log_id'),\n",
    "        'request_timestamp' : log.get('request_timestamp'),\n",
    "        'response_timestamp' : log.get('response_timestamp'),\n",
    "        'assistant_id' : log.get('assistant_id'),\n",
    "        'session_id' : log.get('session_id'),\n",
    "        'customer_id' : log.get('customer_id'),\n",
    "        'skill_id' : log.get('skill_id'),\n",
    "        'request_input' : log.get('request').get('input'),\n",
    "        'response_output' : log.get('response').get('output')\n",
    "    }\n",
    "    counter_while = 0\n",
    "    change_counter = 1 \n",
    "\n",
    "    while change_counter != 0:\n",
    "        if counter_while == 0:\n",
    "            new_data, change_counter = json_expander(base_dict=temp)\n",
    "            counter_while += 1\n",
    "        else: \n",
    "            new_data, change_counter = json_expander(base_dict=new_data)\n",
    "\n",
    "    temp_df = pd.DataFrame([new_data])\n",
    "    #print(temp_df['input_source_id'][0])\n",
    "\n",
    "    df_logs = pd.concat([df_logs, temp_df], ignore_index=True)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in all_logs[0].keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs[500].get('request').get('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs[0].get('request').get('input').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs['request_timestamp'] = pd.to_datetime(df_logs['request_timestamp'], utc=False)#.dt.floor('ms')\n",
    "df_logs['request_timestamp'] = df_logs['request_timestamp'].dt.tz_localize(None)\n",
    "df_logs['response_timestamp'] = pd.to_datetime(df_logs['response_timestamp'], utc=False)#.dt.floor('ms')\n",
    "df_logs['response_timestamp'] = df_logs['response_timestamp'].dt.tz_localize(None)\n",
    "df_logs.sort_values(inplace=True, by=['session_id', 'request_timestamp'], ascending=[True, True])\n",
    "df_logs.reset_index(inplace=True, drop=True)\n",
    "df_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs.to_csv('df_logs.csv', index=False, sep='|')\n",
    "#df_logs.to_parquet('df_logs.gzip', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs.to_excel('df_logs.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs[9000].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs[9001].get('customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs[9000].get('request').get('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs[9000].get('response').get('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_draft = assistant.list_logs(assistant_id=ASSISTANT_ENV_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the logs data in a variable\n",
    "logs_results_data = logs_draft.get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what keys do we have in the dictionay ? \n",
    "logs_results_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_results_data['pagination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(logs_results_data['logs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log results (only one element of the log list)\n",
    "logs_results_data['logs']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311_watsonx_gallery_sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
